# -*- coding: utf-8 -*-
"""Basic K-means customer segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hnap91ZDxigp0ImxxAkrHGaNcOzKPcEG
"""

# Importings
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Load the Data in pandas
df = pd.read_csv('walmart.csv')

# Group by User_ID and calculate total pruchase amount
user_purchase = df.groupby('User_ID')['Purchase'].sum().reset_index()

X = user_purchase[['Purchase']].values

# Feature standarization
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Elbow Method for optimal number of clusters
wcss = []
for i in range(1,11):
    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

plt.figure(figsize=(10, 5))
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.savefig('elbow_curve.png')
plt.show()

# Chosing 3 clusters
kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)
cluster_labels = kmeans.fit_predict(X_scaled)

user_purchase['Cluster']= cluster_labels

plt.figure(figsize=(10, 5))
for i in range(3):
    cluster_data = user_purchase[user_purchase['Cluster'] == i]
    plt.scatter(cluster_data['User_ID'], cluster_data['Purchase'], label=f'Cluster {i}')

plt.title('Customer Segmentation based on Purchase Amount')
plt.xlabel('User ID')
plt.ylabel('Total Purchase Amount')
plt.legend()
plt.savefig('customer_segments.png')
plt.show()

print(user_purchase.groupby('Cluster')['Purchase'].describe())

summary_stats = user_purchase.groupby('Cluster')['Purchase'].describe()

# Output results to CSV
user_purchase.to_csv('customer_segments_K_means.csv', index=False)
summary_stats.to_csv('cluster_summary_stats.csv')